# Criar estruturas de arquivos para o projeto de detecÃ§Ã£o de fake news
import os

# Estrutura do projeto
project_structure = {
    "fake-news-detector/": {
        "README.md": """# Fake News Detector com CrewAI e Perplexity API

Sistema de detecÃ§Ã£o de fake news utilizando multi-agentes com CrewAI, Streamlit e Perplexity API.

## Estrutura do Projeto

```
fake-news-detector/
â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o Streamlit principal
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml        # ConfiguraÃ§Ã£o dos agentes CrewAI
â”‚   â””â”€â”€ tasks.yaml         # ConfiguraÃ§Ã£o das tarefas
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ crew.py        # DefiniÃ§Ã£o da crew e agentes
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ perplexity_tool.py  # Ferramenta para Perplexity API
â”‚   â”‚   â””â”€â”€ url_extractor.py    # ExtraÃ§Ã£o de conteÃºdo de URLs
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py     # FunÃ§Ãµes auxiliares
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ agents.md          # DocumentaÃ§Ã£o dos agentes
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_agents.py     # Testes dos agentes
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â””â”€â”€ .env.example          # Exemplo de variÃ¡veis de ambiente
```

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <repo-url>
cd fake-news-detector
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

3. Configure as variÃ¡veis de ambiente:
```bash
cp .env.example .env
# Edite o arquivo .env com suas chaves de API
```

4. Execute a aplicaÃ§Ã£o:
```bash
streamlit run main.py
```

## Uso

1. Abra a aplicaÃ§Ã£o no navegador
2. Escolha o tipo de entrada (URL ou texto)
3. Insira o conteÃºdo para anÃ¡lise
4. Clique em "Analisar" para processar
5. Visualize os resultados da anÃ¡lise

## Agentes

O sistema utiliza 4 agentes especializados:

- **Content Extractor**: Extrai e limpa conteÃºdo de URLs
- **Fact Checker**: Verifica fatos contra fontes confiÃ¡veis
- **Source Credibility**: Avalia credibilidade da fonte
- **Final Decision**: Sintetiza resultados e toma decisÃ£o final

## Tecnologias

- CrewAI: Framework multi-agente
- Streamlit: Interface web
- Perplexity API: ValidaÃ§Ã£o externa
- Python 3.8+
""",
        
        "requirements.txt": """streamlit==1.29.0
crewai==0.63.6
crewai-tools==0.12.1
requests==2.31.0
beautifulsoup4==4.12.2
python-dotenv==1.0.0
newspaper3k==0.2.8
langchain==0.1.0
openai==1.12.0
pydantic==2.5.0
PyYAML==6.0.1
""",
        
        ".env.example": """# Chaves de API
PERPLEXITY_API_KEY=pplx-your-key-here
OPENAI_API_KEY=sk-your-openai-key-here

# ConfiguraÃ§Ãµes do sistema
DEBUG=True
MAX_RETRIES=3
TIMEOUT=30
""",
        
        "main.py": """import streamlit as st
import os
from dotenv import load_dotenv
from src.agents.crew import FakeNewsDetectorCrew
from src.utils.helpers import validate_url, clean_text

# Carregar variÃ¡veis de ambiente
load_dotenv()

def main():
    st.set_page_config(
        page_title="Detector de Fake News",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” Detector de Fake News")
    st.subheader("Sistema multi-agente para validaÃ§Ã£o de notÃ­cias")
    
    # Sidebar com configuraÃ§Ãµes
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraÃ§Ãµes")
        
        # Verificar se as chaves de API estÃ£o configuradas
        perplexity_key = os.getenv("PERPLEXITY_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        
        if not perplexity_key or not openai_key:
            st.error("âš ï¸ Configure as chaves de API no arquivo .env")
            st.stop()
        
        st.success("âœ… Chaves de API configuradas")
        
        # ConfiguraÃ§Ãµes de anÃ¡lise
        confidence_threshold = st.slider(
            "Limite de confianÃ§a", 0.0, 1.0, 0.7, 0.05
        )
        
        detailed_analysis = st.checkbox("AnÃ¡lise detalhada", value=True)
    
    # Ãrea principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ Entrada")
        
        # SeleÃ§Ã£o do tipo de entrada
        input_type = st.radio(
            "Tipo de entrada:",
            ["URL", "Texto"],
            horizontal=True
        )
        
        if input_type == "URL":
            url = st.text_input(
                "URL da notÃ­cia:",
                placeholder="https://exemplo.com/noticia",
                help="Cole aqui a URL da notÃ­cia que deseja verificar"
            )
            
            if url and st.button("ğŸ” Analisar URL", type="primary"):
                if validate_url(url):
                    with st.spinner("Analisando conteÃºdo..."):
                        result = analyze_content(url, input_type, confidence_threshold, detailed_analysis)
                        display_results(result)
                else:
                    st.error("URL invÃ¡lida. Verifique o formato.")
        
        else:  # Texto
            text = st.text_area(
                "Texto da notÃ­cia:",
                height=200,
                placeholder="Cole aqui o texto da notÃ­cia que deseja verificar...",
                help="Insira o conteÃºdo completo da notÃ­cia"
            )
            
            if text and st.button("ğŸ” Analisar Texto", type="primary"):
                if len(text.strip()) > 50:
                    with st.spinner("Analisando conteÃºdo..."):
                        result = analyze_content(text, input_type, confidence_threshold, detailed_analysis)
                        display_results(result)
                else:
                    st.error("Texto muito curto. Insira pelo menos 50 caracteres.")
    
    with col2:
        st.header("â„¹ï¸ Sobre")
        st.info(
            '''
            **Como funciona:**
            
            1. **ExtraÃ§Ã£o**: O sistema extrai o conteÃºdo da URL ou processa o texto
            2. **VerificaÃ§Ã£o**: MÃºltiplos agentes analisam diferentes aspectos
            3. **ValidaÃ§Ã£o**: Consulta fontes externas via Perplexity API
            4. **DecisÃ£o**: Combina todas as anÃ¡lises para o resultado final
            
            **Agentes ativos:**
            - ğŸ” Extrator de ConteÃºdo
            - âœ… Verificador de Fatos
            - ğŸ›ï¸ Avaliador de Credibilidade
            - âš–ï¸ Decisor Final
            '''
        )

def analyze_content(content, input_type, confidence_threshold, detailed_analysis):
    \"\"\"Analisa o conteÃºdo usando a crew de agentes\"\"\"
    try:
        # Inicializar a crew
        crew = FakeNewsDetectorCrew()
        
        # Preparar inputs
        inputs = {
            'content': content,
            'input_type': input_type,
            'confidence_threshold': confidence_threshold,
            'detailed_analysis': detailed_analysis
        }
        
        # Executar anÃ¡lise
        result = crew.crew().kickoff(inputs=inputs)
        return result
        
    except Exception as e:
        st.error(f"Erro na anÃ¡lise: {str(e)}")
        return None

def display_results(result):
    \"\"\"Exibe os resultados da anÃ¡lise\"\"\"
    if not result:
        return
    
    st.header("ğŸ“Š Resultados da AnÃ¡lise")
    
    # Resultado principal
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if result.get('is_fake', False):
            st.error("ğŸš¨ FAKE NEWS DETECTADA")
        else:
            st.success("âœ… NOTÃCIA VERIFICADA")
    
    with col2:
        confidence = result.get('confidence', 0)
        st.metric("ConfianÃ§a", f"{confidence:.1%}")
    
    with col3:
        risk_level = result.get('risk_level', 'Baixo')
        color = {"Alto": "ğŸ”´", "MÃ©dio": "ğŸŸ¡", "Baixo": "ğŸŸ¢"}
        st.metric("NÃ­vel de Risco", f"{color.get(risk_level, 'âšª')} {risk_level}")
    
    # Detalhes da anÃ¡lise
    if st.expander("ğŸ“‹ Detalhes da AnÃ¡lise", expanded=True):
        
        # AnÃ¡lise por agente
        agents_results = result.get('agents_analysis', {})
        
        for agent_name, analysis in agents_results.items():
            with st.container():
                st.subheader(f"ğŸ¤– {agent_name}")
                st.write(analysis.get('summary', 'Nenhuma anÃ¡lise disponÃ­vel'))
                
                if analysis.get('evidence'):
                    st.write("**EvidÃªncias:**")
                    for evidence in analysis['evidence']:
                        st.write(f"- {evidence}")
    
    # RecomendaÃ§Ãµes
    if result.get('recommendations'):
        st.subheader("ğŸ’¡ RecomendaÃ§Ãµes")
        for rec in result['recommendations']:
            st.write(f"â€¢ {rec}")

if __name__ == "__main__":
    main()
""",
    },
    
    "config/": {
        "agents.yaml": """content_extractor:
  role: "Especialista em ExtraÃ§Ã£o de ConteÃºdo"
  goal: "Extrair e limpar conteÃºdo de URLs ou processar texto fornecido, preparando-o para anÃ¡lise"
  backstory: |
    VocÃª Ã© um especialista em processamento de conteÃºdo web com vasta experiÃªncia em extraÃ§Ã£o 
    de texto de diferentes formatos e fontes. Sua missÃ£o Ã© garantir que o conteÃºdo seja 
    limpo, estruturado e pronto para anÃ¡lise pelos outros agentes.
  verbose: true
  memory: true
  max_iter: 3
  allow_delegation: false

fact_checker:
  role: "Verificador de Fatos Especializado"
  goal: "Verificar a veracidade das informaÃ§Ãµes apresentadas usando fontes confiÃ¡veis e cross-referencing"
  backstory: |
    VocÃª Ã© um jornalista investigativo experiente com mais de 15 anos verificando fatos. 
    VocÃª tem acesso a mÃºltiplas fontes de informaÃ§Ã£o e Ã© especialista em identificar 
    discrepÃ¢ncias, contradiÃ§Ãµes e informaÃ§Ãµes falsas. VocÃª sempre busca evidÃªncias 
    concretas antes de fazer qualquer julgamento.
  verbose: true
  memory: true
  max_iter: 5
  allow_delegation: true

source_credibility:
  role: "Analista de Credibilidade de Fontes"
  goal: "Avaliar a credibilidade, reputaÃ§Ã£o e viÃ©s de fontes de informaÃ§Ã£o"
  backstory: |
    VocÃª Ã© um especialista em anÃ¡lise de mÃ­dia com PhD em ComunicaÃ§Ã£o Social. 
    Sua especialidade Ã© avaliar a credibilidade de fontes, identificar vieses 
    polÃ­ticos ou comerciais, e determinar a confiabilidade histÃ³rica de 
    veÃ­culos de comunicaÃ§Ã£o.
  verbose: true
  memory: true
  max_iter: 4
  allow_delegation: false

final_decision:
  role: "Analista Senior de DecisÃ£o"
  goal: "Sintetizar todas as anÃ¡lises e tomar decisÃ£o final sobre autenticidade do conteÃºdo"
  backstory: |
    VocÃª Ã© um analista senior com mais de 20 anos de experiÃªncia em anÃ¡lise de 
    informaÃ§Ãµes e tomada de decisÃµes crÃ­ticas. VocÃª Ã© responsÃ¡vel por combinar 
    mÃºltiplas perspectivas, pesar evidÃªncias e chegar a conclusÃµes fundamentadas 
    sobre a veracidade de informaÃ§Ãµes.
  verbose: true
  memory: true
  max_iter: 3
  allow_delegation: false
""",
        
        "tasks.yaml": """extract_content:
  description: |
    Extrair e processar o conteÃºdo fornecido:
    
    Se for URL:
    1. Acessar a URL e extrair o conteÃºdo principal
    2. Remover elementos desnecessÃ¡rios (ads, menus, etc.)
    3. Identificar tÃ­tulo, autor, data de publicaÃ§Ã£o
    4. Extrair o texto principal do artigo
    
    Se for texto:
    1. Limpar e estruturar o texto fornecido
    2. Identificar elementos-chave (tÃ­tulo, pontos principais)
    3. Verificar se hÃ¡ metadados disponÃ­veis
    
    ConteÃºdo: {content}
    Tipo: {input_type}
  expected_output: |
    Um relatÃ³rio estruturado contendo:
    - TÃ­tulo da notÃ­cia
    - ConteÃºdo principal limpo e estruturado  
    - Metadados disponÃ­veis (autor, data, fonte)
    - Resumo executivo do conteÃºdo
    - Pontos principais identificados
  agent: content_extractor

verify_facts:
  description: |
    Verificar a veracidade dos fatos apresentados no conteÃºdo extraÃ­do:
    
    1. Identificar claims especÃ­ficos e verificÃ¡veis
    2. Usar a ferramenta Perplexity para buscar informaÃ§Ãµes de fontes confiÃ¡veis
    3. Cross-referenciar informaÃ§Ãµes com mÃºltiplas fontes
    4. Identificar inconsistÃªncias ou contradiÃ§Ãµes
    5. Verificar estatÃ­sticas, datas e eventos mencionados
    6. Avaliar se as informaÃ§Ãµes estÃ£o atualizadas
    
    Use anÃ¡lise detalhada: {detailed_analysis}
    ConteÃºdo para verificaÃ§Ã£o serÃ¡ fornecido pelo agente anterior.
  expected_output: |
    RelatÃ³rio de verificaÃ§Ã£o de fatos contendo:
    - Lista de claims identificados
    - Status de verificaÃ§Ã£o para cada claim (Verdadeiro/Falso/Inconclusivo)
    - Fontes utilizadas para verificaÃ§Ã£o
    - EvidÃªncias encontradas (a favor ou contra)
    - NÃ­vel de confianÃ§a para cada verificaÃ§Ã£o
    - InconsistÃªncias identificadas
  agent: fact_checker
  context: [extract_content]

assess_source:
  description: |
    Avaliar a credibilidade da fonte de informaÃ§Ã£o:
    
    1. Analisar a reputaÃ§Ã£o histÃ³rica da fonte
    2. Verificar registro de precisÃ£o em reportagens anteriores
    3. Identificar possÃ­veis vieses polÃ­ticos, comerciais ou ideolÃ³gicos
    4. Avaliar transparÃªncia editorial e metodologia jornalÃ­stica
    5. Verificar se a fonte segue padrÃµes Ã©ticos de jornalismo
    6. Analisar financiamento e propriedade da fonte
    
    Considerar limite de confianÃ§a: {confidence_threshold}
  expected_output: |
    AnÃ¡lise de credibilidade contendo:
    - Score de credibilidade (0-100)
    - HistÃ³rico de precisÃ£o da fonte
    - Vieses identificados
    - TransparÃªncia editorial
    - PadrÃµes jornalÃ­sticos seguidos
    - RecomendaÃ§Ãµes sobre confiabilidade
    - Fatores de risco identificados
  agent: source_credibility
  context: [extract_content]

make_decision:
  description: |
    Sintetizar todas as anÃ¡lises e tomar decisÃ£o final sobre a autenticidade:
    
    1. Revisar anÃ¡lise de extraÃ§Ã£o de conteÃºdo
    2. Considerar resultados da verificaÃ§Ã£o de fatos
    3. Incorporar avaliaÃ§Ã£o de credibilidade da fonte  
    4. Aplicar peso apropriado a cada anÃ¡lise
    5. Determstar classificaÃ§Ã£o final (Fake News/Verificado/Inconclusivo)
    6. Calcular nÃ­vel de confianÃ§a na decisÃ£o
    7. Fornecer recomendaÃ§Ãµes para o usuÃ¡rio
    
    Limite de confianÃ§a configurado: {confidence_threshold}
  expected_output: |
    DecisÃ£o final estruturada contendo:
    - ClassificaÃ§Ã£o: FAKE NEWS / VERIFICADO / INCONCLUSIVO
    - NÃ­vel de confianÃ§a (0-100%)
    - NÃ­vel de risco (Alto/MÃ©dio/Baixo)
    - Resumo executivo da anÃ¡lise
    - Principais evidÃªncias que suportam a decisÃ£o
    - RecomendaÃ§Ãµes para o usuÃ¡rio
    - PrÃ³ximos passos sugeridos
    - LimitaÃ§Ãµes da anÃ¡lise
  agent: final_decision
  context: [extract_content, verify_facts, assess_source]
"""
    },
    
    "src/": {
        "__init__.py": "",
        "agents/": {
            "__init__.py": "",
            "crew.py": """from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task
from crewai_tools import SerperDevTool
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List
import yaml
import os
from ..tools.perplexity_tool import PerplexityTool
from ..tools.url_extractor import URLExtractorTool

@CrewBase
class FakeNewsDetectorCrew():
    \"\"\"Crew para detecÃ§Ã£o de fake news usando mÃºltiplos agentes especializados\"\"\"
    
    def __init__(self):
        self.agents_config = self._load_config('config/agents.yaml')
        self.tasks_config = self._load_config('config/tasks.yaml')
    
    def _load_config(self, file_path):
        \"\"\"Carrega configuraÃ§Ã£o YAML\"\"\"
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return yaml.safe_load(file)
        except FileNotFoundError:
            raise FileNotFoundError(f"Arquivo de configuraÃ§Ã£o nÃ£o encontrado: {file_path}")
    
    @agent
    def content_extractor(self) -> Agent:
        \"\"\"Agente responsÃ¡vel por extrair conteÃºdo de URLs ou processar texto\"\"\"
        return Agent(
            config=self.agents_config['content_extractor'],
            tools=[URLExtractorTool()],
            verbose=True
        )
    
    @agent  
    def fact_checker(self) -> Agent:
        \"\"\"Agente responsÃ¡vel por verificar fatos usando fontes externas\"\"\"
        return Agent(
            config=self.agents_config['fact_checker'],
            tools=[PerplexityTool(), SerperDevTool()],
            verbose=True
        )
    
    @agent
    def source_credibility(self) -> Agent:
        \"\"\"Agente responsÃ¡vel por avaliar credibilidade da fonte\"\"\"
        return Agent(
            config=self.agents_config['source_credibility'],
            tools=[PerplexityTool()],
            verbose=True
        )
    
    @agent
    def final_decision(self) -> Agent:
        \"\"\"Agente responsÃ¡vel pela decisÃ£o final\"\"\"
        return Agent(
            config=self.agents_config['final_decision'],
            verbose=True
        )
    
    @task
    def extract_content_task(self) -> Task:
        \"\"\"Tarefa de extraÃ§Ã£o de conteÃºdo\"\"\"
        return Task(
            config=self.tasks_config['extract_content'],
            agent=self.content_extractor()
        )
    
    @task
    def verify_facts_task(self) -> Task:
        \"\"\"Tarefa de verificaÃ§Ã£o de fatos\"\"\"
        return Task(
            config=self.tasks_config['verify_facts'],
            agent=self.fact_checker()
        )
    
    @task
    def assess_source_task(self) -> Task:
        \"\"\"Tarefa de avaliaÃ§Ã£o de credibilidade\"\"\"
        return Task(
            config=self.tasks_config['assess_source'],
            agent=self.source_credibility()
        )
    
    @task
    def make_decision_task(self) -> Task:
        \"\"\"Tarefa de decisÃ£o final\"\"\"
        return Task(
            config=self.tasks_config['make_decision'],
            agent=self.final_decision(),
            output_file='analysis_result.md'
        )
    
    @crew
    def crew(self) -> Crew:
        \"\"\"Cria a crew de detecÃ§Ã£o de fake news\"\"\"
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
            planning=True,
            planning_llm=None,  # Usar LLM padrÃ£o para planejamento
            memory=True
        )
"""
        },
        
        "tools/": {
            "__init__.py": "",
            "perplexity_tool.py": """from crewai_tools import BaseTool
from typing import Optional, Type, Any
from pydantic import BaseModel, Field
import requests
import os
from dotenv import load_dotenv

load_dotenv()

class PerplexityInput(BaseModel):
    \"\"\"Input para a ferramenta Perplexity\"\"\"
    query: str = Field(description="Query de pesquisa para validaÃ§Ã£o de fatos")
    model: Optional[str] = Field(
        default="llama-3.1-sonar-small-128k-online", 
        description="Modelo Perplexity a ser usado"
    )

class PerplexityTool(BaseTool):
    \"\"\"Ferramenta para consultar a API do Perplexity para verificaÃ§Ã£o de fatos\"\"\"
    
    name: str = "perplexity_search"
    description: str = (
        "Ferramenta para buscar informaÃ§Ãµes e verificar fatos usando a API do Perplexity. "
        "Ãštil para cross-referencing de informaÃ§Ãµes com fontes confiÃ¡veis online."
    )
    args_schema: Type[BaseModel] = PerplexityInput
    
    def __init__(self):
        super().__init__()
        self.api_key = os.getenv("PERPLEXITY_API_KEY")
        self.base_url = "https://api.perplexity.ai/chat/completions"
        
        if not self.api_key:
            raise ValueError("PERPLEXITY_API_KEY nÃ£o encontrada nas variÃ¡veis de ambiente")
    
    def _run(
        self, 
        query: str, 
        model: str = "llama-3.1-sonar-small-128k-online"
    ) -> str:
        \"\"\"Executa consulta na API do Perplexity\"\"\"
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "VocÃª Ã© um assistente especializado em verificaÃ§Ã£o de fatos. "
                            "ForneÃ§a informaÃ§Ãµes precisas, atualizadas e cite as fontes sempre que possÃ­vel. "
                            "Se nÃ£o tiver certeza sobre algo, indique explicitamente."
                        )
                    },
                    {
                        "role": "user", 
                        "content": query
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.2,
                "top_p": 0.9,
                "return_citations": True,
                "search_domain_filter": ["reputable_sources"],
                "return_related_questions": False
            }
            
            response = requests.post(
                self.base_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            response.raise_for_status()
            
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                
                # Adicionar citaÃ§Ãµes se disponÃ­veis
                if "citations" in result:
                    citations = result.get("citations", [])
                    if citations:
                        content += "\\n\\n**Fontes:**\\n"
                        for i, citation in enumerate(citations[:5], 1):
                            content += f"{i}. {citation}\\n"
                
                return content
            else:
                return "NÃ£o foi possÃ­vel obter resposta da API Perplexity"
                
        except requests.exceptions.RequestException as e:
            return f"Erro na requisiÃ§Ã£o para Perplexity API: {str(e)}"
        except Exception as e:
            return f"Erro inesperado na ferramenta Perplexity: {str(e)}"
    
    async def _arun(self, query: str, model: str = "llama-3.1-sonar-small-128k-online") -> str:
        \"\"\"VersÃ£o assÃ­ncrona da execuÃ§Ã£o\"\"\"
        # Para implementaÃ§Ã£o assÃ­ncrona futura
        return self._run(query, model)
""",
            
            "url_extractor.py": """from crewai_tools import BaseTool
from typing import Type
from pydantic import BaseModel, Field
import requests
from bs4 import BeautifulSoup
from newspaper import Article
import re
from urllib.parse import urlparse, urljoin
import time

class URLExtractorInput(BaseModel):
    \"\"\"Input para extraÃ§Ã£o de conteÃºdo de URL\"\"\"
    url: str = Field(description="URL da notÃ­cia para extrair conteÃºdo")

class URLExtractorTool(BaseTool):
    \"\"\"Ferramenta para extrair conteÃºdo limpo de URLs de notÃ­cias\"\"\"
    
    name: str = "url_extractor"
    description: str = (
        "Extrai conteÃºdo principal de URLs de notÃ­cias, incluindo tÃ­tulo, "
        "texto do artigo, autor, data de publicaÃ§Ã£o e metadados relevantes."
    )
    args_schema: Type[BaseModel] = URLExtractorInput
    
    def _run(self, url: str) -> str:
        \"\"\"Extrai conteÃºdo da URL fornecida\"\"\"
        
        try:
            # Validar URL
            if not self._is_valid_url(url):
                return "URL invÃ¡lida fornecida"
            
            # Tentar primeiro com newspaper3k
            try:
                article = Article(url)
                article.download()
                article.parse()
                
                # Extrair informaÃ§Ãµes bÃ¡sicas
                title = article.title or "TÃ­tulo nÃ£o encontrado"
                text = article.text or ""
                authors = article.authors or []
                publish_date = article.publish_date
                
                # Se newspaper3k nÃ£o conseguir extrair texto, usar BeautifulSoup
                if not text.strip():
                    text = self._extract_with_beautifulsoup(url)
                
                # Limpar texto
                cleaned_text = self._clean_text(text)
                
                # Formatear data
                date_str = publish_date.strftime("%Y-%m-%d") if publish_date else "Data nÃ£o encontrada"
                
                # Construir resultado
                result = f"""**CONTEÃšDO EXTRAÃDO DA URL**

**URL:** {url}
**TÃ­tulo:** {title}
**Autor(es):** {', '.join(authors) if authors else 'NÃ£o informado'}
**Data de PublicaÃ§Ã£o:** {date_str}

**CONTEÃšDO PRINCIPAL:**
{cleaned_text}

**METADADOS:**
- Tamanho do texto: {len(cleaned_text)} caracteres
- NÃºmero de parÃ¡grafos: {len(cleaned_text.split('\\n\\n'))}
- DomÃ­nio: {urlparse(url).netloc}
"""
                
                return result
                
            except Exception as newspaper_error:
                # Fallback para BeautifulSoup se newspaper3k falhar
                return self._extract_with_beautifulsoup(url)
                
        except Exception as e:
            return f"Erro ao extrair conteÃºdo da URL: {str(e)}"
    
    def _is_valid_url(self, url: str) -> bool:
        \"\"\"Valida se a URL Ã© vÃ¡lida\"\"\"
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except:
            return False
    
    def _extract_with_beautifulsoup(self, url: str) -> str:
        \"\"\"Extrai conteÃºdo usando BeautifulSoup como fallback\"\"\"
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Remover scripts, styles, etc.
            for script in soup(["script", "style", "nav", "header", "footer", "aside"]):
                script.decompose()
            
            # Tentar encontrar o conteÃºdo principal
            content_selectors = [
                'article', '[role="main"]', '.content', '.post-content', 
                '.entry-content', '.article-body', '.story-body'
            ]
            
            main_content = None
            for selector in content_selectors:
                main_content = soup.select_one(selector)
                if main_content:
                    break
            
            if not main_content:
                main_content = soup.find('body')
            
            # Extrair tÃ­tulo
            title_tag = soup.find('title') or soup.find('h1')
            title = title_tag.get_text().strip() if title_tag else "TÃ­tulo nÃ£o encontrado"
            
            # Extrair texto
            text = main_content.get_text() if main_content else ""
            cleaned_text = self._clean_text(text)
            
            result = f"""**CONTEÃšDO EXTRAÃDO (FALLBACK)**

**URL:** {url}
**TÃ­tulo:** {title}
**MÃ©todo:** BeautifulSoup (fallback)

**CONTEÃšDO PRINCIPAL:**
{cleaned_text}

**METADADOS:**
- Tamanho do texto: {len(cleaned_text)} caracteres
- DomÃ­nio: {urlparse(url).netloc}
"""
            
            return result
            
        except Exception as e:
            return f"Erro no fallback de extraÃ§Ã£o: {str(e)}"
    
    def _clean_text(self, text: str) -> str:
        \"\"\"Limpa e formata o texto extraÃ­do\"\"\"
        if not text:
            return "Texto nÃ£o encontrado"
        
        # Remover espaÃ§os extras e quebras de linha desnecessÃ¡rias
        text = re.sub(r'\\s+', ' ', text)
        text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)
        
        # Remover padrÃµes comuns de menu/navegaÃ§Ã£o
        patterns_to_remove = [
            r'Home\\s*>.*?\\n',
            r'Menu\\s*\\n',
            r'Compartilhar.*?\\n',
            r'Imprimir.*?\\n',
        ]
        
        for pattern in patterns_to_remove:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        # Limitar tamanho se muito grande
        if len(text) > 10000:
            text = text[:10000] + "\\n\\n[TEXTO TRUNCADO...]"
        
        return text.strip()
    
    async def _arun(self, url: str) -> str:
        \"\"\"VersÃ£o assÃ­ncrona\"\"\"
        return self._run(url)
"""
        },
        
        "utils/": {
            "__init__.py": "",
            "helpers.py": """import re
from urllib.parse import urlparse
from typing import Dict, Any, List

def validate_url(url: str) -> bool:
    \"\"\"Valida se uma URL estÃ¡ em formato vÃ¡lido\"\"\"
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

def clean_text(text: str) -> str:
    \"\"\"Limpa texto removendo caracteres especiais e formataÃ§Ã£o\"\"\"
    if not text:
        return ""
    
    # Remover espaÃ§os extras
    text = re.sub(r'\\s+', ' ', text)
    
    # Remover caracteres de controle
    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)
    
    return text.strip()

def extract_key_points(text: str, max_points: int = 5) -> List[str]:
    \"\"\"Extrai pontos-chave do texto\"\"\"
    if not text:
        return []
    
    # Dividir em sentenÃ§as
    sentences = re.split(r'[.!?]+', text)
    
    # Filtrar sentenÃ§as muito curtas ou muito longas
    filtered_sentences = [
        s.strip() for s in sentences 
        if 20 <= len(s.strip()) <= 200
    ]
    
    # Retornar as primeiras sentenÃ§as (simplificado)
    return filtered_sentences[:max_points]

def calculate_confidence_score(factors: Dict[str, float]) -> float:
    \"\"\"Calcula score de confianÃ§a baseado em mÃºltiplos fatores\"\"\"
    if not factors:
        return 0.0
    
    # Pesos para diferentes fatores
    weights = {
        'source_credibility': 0.3,
        'fact_verification': 0.4,
        'content_quality': 0.2,
        'consistency': 0.1
    }
    
    weighted_score = 0.0
    total_weight = 0.0
    
    for factor, score in factors.items():
        if factor in weights:
            weighted_score += score * weights[factor]
            total_weight += weights[factor]
    
    return weighted_score / total_weight if total_weight > 0 else 0.0

def format_analysis_result(result: Dict[str, Any]) -> str:
    \"\"\"Formata resultado da anÃ¡lise para exibiÃ§Ã£o\"\"\"
    if not result:
        return "Nenhum resultado disponÃ­vel"
    
    formatted = f\"\"\"
# AnÃ¡lise de Fake News

## Resultado: {result.get('classification', 'NÃ£o determinado')}
**ConfianÃ§a:** {result.get('confidence', 0):.1%}
**NÃ­vel de Risco:** {result.get('risk_level', 'NÃ£o avaliado')}

## Resumo
{result.get('summary', 'Resumo nÃ£o disponÃ­vel')}

## EvidÃªncias
{chr(10).join(f"â€¢ {evidence}" for evidence in result.get('evidence', []))}

## RecomendaÃ§Ãµes
{chr(10).join(f"â€¢ {rec}" for rec in result.get('recommendations', []))}
\"\"\"
    
    return formatted.strip()

def get_risk_level(confidence: float, is_fake: bool) -> str:
    \"\"\"Determina nÃ­vel de risco baseado na confianÃ§a e classificaÃ§Ã£o\"\"\"
    if is_fake:
        if confidence >= 0.8:
            return "Alto"
        elif confidence >= 0.6:
            return "MÃ©dio"
        else:
            return "Baixo"
    else:
        if confidence >= 0.8:
            return "Baixo"
        elif confidence >= 0.6:
            return "MÃ©dio"
        else:
            return "Alto"  # Baixa confianÃ§a em notÃ­cia real tambÃ©m Ã© risco

def sanitize_input(text: str, max_length: int = 50000) -> str:
    \"\"\"Sanitiza entrada do usuÃ¡rio\"\"\"
    if not text:
        return ""
    
    # Limitar tamanho
    if len(text) > max_length:
        text = text[:max_length]
    
    # Remover caracteres perigosos
    text = re.sub(r'[<>\"\'&]', '', text)
    
    return text.strip()
"""
        }
    },
    
    "docs/": {
        "agents.md": """# DocumentaÃ§Ã£o dos Agentes - Sistema de DetecÃ§Ã£o de Fake News

## VisÃ£o Geral

Este sistema utiliza uma arquitetura multi-agente baseada no framework CrewAI para detectar fake news de forma colaborativa e especializada. Cada agente tem uma responsabilidade especÃ­fica no pipeline de anÃ¡lise.

## Arquitetura do Sistema

### 1. Content Extractor Agent (Agente Extrator de ConteÃºdo)

**Papel:** Especialista em ExtraÃ§Ã£o de ConteÃºdo  
**Objetivo:** Extrair e limpar conteÃºdo de URLs ou processar texto fornecido

#### Responsabilidades:
- Acessar URLs e extrair conteÃºdo principal
- Remover elementos desnecessÃ¡rios (advertisements, menus, etc.)
- Identificar metadados (tÃ­tulo, autor, data)
- Estruturar o conteÃºdo para anÃ¡lise
- Processar texto diretamente fornecido

#### Ferramentas Utilizadas:
- `URLExtractorTool`: ExtraÃ§Ã£o de conteÃºdo web
- `newspaper3k`: Parsing avanÃ§ado de artigos
- `BeautifulSoup`: Fallback para extraÃ§Ã£o HTML

#### ConfiguraÃ§Ãµes:
- `max_iter`: 3
- `allow_delegation`: false
- `memory`: true

---

### 2. Fact Checker Agent (Agente Verificador de Fatos)

**Papel:** Verificador de Fatos Especializado  
**Objetivo:** Verificar veracidade das informaÃ§Ãµes usando fontes confiÃ¡veis

#### Responsabilidades:
- Identificar claims especÃ­ficos e verificÃ¡veis
- Buscar informaÃ§Ãµes em fontes confiÃ¡veis
- Cross-referenciar dados com mÃºltiplas fontes
- Identificar inconsistÃªncias temporais
- Verificar estatÃ­sticas e eventos mencionados

#### Ferramentas Utilizadas:
- `PerplexityTool`: Consulta Ã  API Perplexity para fact-checking
- `SerperDevTool`: Busca web adicional
- Acesso a bases de dados de fact-checking

#### ConfiguraÃ§Ãµes:
- `max_iter`: 5
- `allow_delegation`: true
- `memory`: true

---

### 3. Source Credibility Agent (Agente de Credibilidade)

**Papel:** Analista de Credibilidade de Fontes  
**Objetivo:** Avaliar credibilidade, reputaÃ§Ã£o e viÃ©s das fontes

#### Responsabilidades:
- Analisar histÃ³rico de precisÃ£o da fonte
- Identificar vieses polÃ­ticos/comerciais
- Verificar transparÃªncia editorial
- Avaliar metodologia jornalÃ­stica
- Analisar financiamento e propriedade

#### Ferramentas Utilizadas:
- `PerplexityTool`: Pesquisa sobre reputaÃ§Ã£o de fontes
- Bases de dados de credibilidade de mÃ­dia
- AnÃ¡lise de padrÃµes editoriais

#### ConfiguraÃ§Ãµes:
- `max_iter`: 4
- `allow_delegation`: false
- `memory`: true

---

### 4. Final Decision Agent (Agente de DecisÃ£o Final)

**Papel:** Analista Senior de DecisÃ£o  
**Objetivo:** Sintetizar anÃ¡lises e tomar decisÃ£o final sobre autenticidade

#### Responsabilidades:
- Combinar resultados de todos os agentes
- Aplicar pesos apropriados Ã s anÃ¡lises
- Calcular nÃ­vel de confianÃ§a
- Determinar classificaÃ§Ã£o final
- Fornecer recomendaÃ§Ãµes ao usuÃ¡rio

#### ConfiguraÃ§Ãµes:
- `max_iter`: 3
- `allow_delegation`: false
- `memory`: true

---

## Fluxo de Trabalho

### Processo Sequential

1. **ExtraÃ§Ã£o** â†’ Content Extractor processa entrada
2. **VerificaÃ§Ã£o** â†’ Fact Checker analisa claims (paralelo)
3. **Credibilidade** â†’ Source Credibility avalia fonte (paralelo)  
4. **DecisÃ£o** â†’ Final Decision sintetiza resultados

### InterdependÃªncias

- Fact Checker e Source Credibility dependem do Content Extractor
- Final Decision depende de todos os agentes anteriores
- Contexto Ã© compartilhado entre agentes relevantes

---

## ConfiguraÃ§Ãµes de Qualidade

### Limites de ConfianÃ§a
- **Alto**: â‰¥ 80% - DecisÃ£o confiÃ¡vel
- **MÃ©dio**: 60-79% - Cautela recomendada  
- **Baixo**: < 60% - AnÃ¡lise adicional necessÃ¡ria

### NÃ­veis de Risco
- **Alto**: Fake news com alta confianÃ§a
- **MÃ©dio**: Resultados inconclusivos
- **Baixo**: ConteÃºdo verificado como autÃªntico

---

## Boas PrÃ¡ticas de Desenvolvimento

### 1. ConfiguraÃ§Ã£o de Agentes

```yaml
agent_name:
  role: "Papel especÃ­fico e claro"
  goal: "Objetivo mensurÃ¡vel"
  backstory: "Contexto e expertise"
  verbose: true
  memory: true
  max_iter: 3-5
  allow_delegation: true/false
```

### 2. Design de Tasks

```yaml
task_name:
  description: "InstruÃ§Ãµes detalhadas e especÃ­ficas"
  expected_output: "Formato estruturado esperado"
  agent: agent_responsavel
  context: [dependencias]
```

### 3. Gerenciamento de MemÃ³ria

- Ativar memÃ³ria para contexto entre execuÃ§Ãµes
- Limpar memÃ³ria periodicamente para evitar poluiÃ§Ã£o
- Usar contexto especÃ­fico para dependÃªncias

### 4. Tratamento de Erros

- Implementar retry logic para chamadas de API
- Validar entradas antes do processamento
- Fornecer fallbacks para falhas de ferramentas

### 5. Monitoramento e Logs

- Log detalhado de cada etapa do processo
- MÃ©tricas de performance por agente
- Tracking de custos de API

---

## Extensibilidade

### Adicionando Novos Agentes

1. Definir papel e responsabilidades especÃ­ficas
2. Criar configuraÃ§Ã£o YAML
3. Implementar classe do agente
4. Definir ferramentas necessÃ¡rias
5. Configurar dependÃªncias e contexto

### Melhorias Futuras

- **Sentiment Analysis Agent**: AnÃ¡lise de tom e sentimento
- **Image Verification Agent**: VerificaÃ§Ã£o de imagens
- **Social Media Agent**: AnÃ¡lise de propagaÃ§Ã£o em redes sociais
- **Legal Compliance Agent**: VerificaÃ§Ã£o de aspectos legais

---

## Troubleshooting

### Problemas Comuns

1. **Timeout de API**: Aumentar timeout, implementar retry
2. **MemÃ³ria insuficiente**: Limpar contexto, otimizar prompts
3. **Rate limiting**: Implementar backoff exponencial
4. **Qualidade baixa**: Ajustar prompts, aumentar max_iter

### MÃ©tricas de Qualidade

- **PrecisÃ£o**: % de classificaÃ§Ãµes corretas
- **Recall**: % de fake news detectadas
- **F1-Score**: Harmonic mean de precisÃ£o e recall
- **Tempo de resposta**: LatÃªncia mÃ©dia do pipeline
"""
    },
    
    "tests/": {
        "__init__.py": "",
        "test_agents.py": """import pytest
import sys
import os

# Adicionar src ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from agents.crew import FakeNewsDetectorCrew
from tools.perplexity_tool import PerplexityTool
from tools.url_extractor import URLExtractorTool
from utils.helpers import validate_url, clean_text, calculate_confidence_score

class TestCrewConfiguration:
    \"\"\"Testes para configuraÃ§Ã£o da crew\"\"\"
    
    def test_crew_initialization(self):
        \"\"\"Testa inicializaÃ§Ã£o da crew\"\"\"
        crew = FakeNewsDetectorCrew()
        assert crew is not None
        assert hasattr(crew, 'agents_config')
        assert hasattr(crew, 'tasks_config')
    
    def test_agents_creation(self):
        \"\"\"Testa criaÃ§Ã£o dos agentes\"\"\"
        crew = FakeNewsDetectorCrew()
        
        # Verificar se todos os agentes podem ser criados
        content_extractor = crew.content_extractor()
        fact_checker = crew.fact_checker()
        source_credibility = crew.source_credibility()
        final_decision = crew.final_decision()
        
        assert content_extractor is not None
        assert fact_checker is not None
        assert source_credibility is not None
        assert final_decision is not None

class TestTools:
    \"\"\"Testes para as ferramentas\"\"\"
    
    def test_perplexity_tool_initialization(self):
        \"\"\"Testa inicializaÃ§Ã£o da ferramenta Perplexity\"\"\"
        # Mock da chave de API para teste
        os.environ['PERPLEXITY_API_KEY'] = 'test_key'
        
        tool = PerplexityTool()
        assert tool.name == "perplexity_search"
        assert tool.api_key == 'test_key'
    
    def test_url_extractor_tool(self):
        \"\"\"Testa ferramenta de extraÃ§Ã£o de URL\"\"\"
        tool = URLExtractorTool()
        assert tool.name == "url_extractor"
        
        # Teste com URL invÃ¡lida
        result = tool._run("invalid_url")
        assert "invÃ¡lida" in result.lower()

class TestHelpers:
    \"\"\"Testes para funÃ§Ãµes auxiliares\"\"\"
    
    def test_validate_url(self):
        \"\"\"Testa validaÃ§Ã£o de URLs\"\"\"
        assert validate_url("https://example.com") == True
        assert validate_url("http://example.com") == True
        assert validate_url("invalid") == False
        assert validate_url("") == False
    
    def test_clean_text(self):
        \"\"\"Testa limpeza de texto\"\"\"
        dirty_text = "  Texto   com    espaÃ§os   extras  \\n\\n  "
        clean = clean_text(dirty_text)
        assert clean == "Texto com espaÃ§os extras"
        
        assert clean_text("") == ""
        assert clean_text(None) == ""
    
    def test_confidence_score_calculation(self):
        \"\"\"Testa cÃ¡lculo de score de confianÃ§a\"\"\"
        factors = {
            'source_credibility': 0.8,
            'fact_verification': 0.9,
            'content_quality': 0.7,
            'consistency': 0.6
        }
        
        score = calculate_confidence_score(factors)
        assert 0.0 <= score <= 1.0
        
        # Teste com fatores vazios
        assert calculate_confidence_score({}) == 0.0

class TestIntegration:
    \"\"\"Testes de integraÃ§Ã£o\"\"\"
    
    @pytest.mark.integration
    def test_crew_execution_flow(self):
        \"\"\"Testa fluxo de execuÃ§Ã£o da crew (mock)\"\"\"
        # Este teste requer configuraÃ§Ã£o completa
        # Implementar quando ambiente de teste estiver pronto
        pass
    
    @pytest.mark.integration 
    def test_api_connectivity(self):
        \"\"\"Testa conectividade com APIs externas\"\"\"
        # Implementar testes de conectividade quando necessÃ¡rio
        pass

# Fixtures para testes
@pytest.fixture
def sample_crew():
    \"\"\"Fixture para crew de exemplo\"\"\"
    return FakeNewsDetectorCrew()

@pytest.fixture
def sample_url():
    \"\"\"Fixture para URL de exemplo\"\"\"
    return "https://example.com/news-article"

@pytest.fixture
def sample_text():
    \"\"\"Fixture para texto de exemplo\"\"\"
    return '''
    Este Ã© um exemplo de artigo de notÃ­cia para teste.
    ContÃ©m informaÃ§Ãµes que podem ser verificadas pelos agentes.
    O texto tem tamanho suficiente para anÃ¡lise.
    '''

if __name__ == "__main__":
    pytest.main([__file__])
"""
    }
}

def create_file_structure(base_path, structure):
    """Cria estrutura de arquivos e diretÃ³rios"""
    for name, content in structure.items():
        path = os.path.join(base_path, name)
        
        if isinstance(content, dict):
            # Ã‰ um diretÃ³rio
            os.makedirs(path, exist_ok=True)
            create_file_structure(path, content)
        else:
            # Ã‰ um arquivo
            os.makedirs(os.path.dirname(path), exist_ok=True)
            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)

# Criar estrutura do projeto
base_dir = "fake-news-detector"
create_file_structure(".", project_structure)

print("âœ… Estrutura do projeto criada com sucesso!")
print(f"ğŸ“ DiretÃ³rio principal: {base_dir}")
print("\nğŸ“‹ PrÃ³ximos passos:")
print("1. cd fake-news-detector")
print("2. pip install -r requirements.txt")
print("3. cp .env.example .env")
print("4. Configure suas chaves de API no arquivo .env")
print("5. streamlit run main.py")